---
layout: article
title:  "「论文阅读」 A Survey of Deep Learning-based Object Detection"
date:   2020-04-11 00:06:40 +0800
key: Object-survey
aside:
  toc: true
category: [AI, CV, detection, paper_reading]
---
<span id='head'></span>   
>
论文发表时间：2019-07-11            
作者：Licheng Jiao, Fan Zhang, Fang Liu, Shuyuan Yang, Lingling Li, Zhixi Feng, Rong Qu       
论文地址：<https://arxiv.org/abs/1907.09408>   

<!--more-->   

>目标检测：通过计算机视觉相关技术，从图像中检测语义对象(如人、车、物等)；     

# 1 Abstract  
文章汇总最新的基于深度学习的目标检测方法、数据集，但不介绍基础知识及深入讨论；    
提高处理速度，比如 anchor-free；提升精度，解决复杂场景(小目标,遮挡)，结合单阶段和两阶段模型，改进后处理——NMS，解决正负不平衡问题；

# 2 backbone
骨干网作为目标检测任务的特征提取模块；通常分类任务的网络，去掉了最后一个完全连接的层`为什么是去掉最后一层全连接层`{:.warning}；常用的有密集型（如 ResNet、ResNeXt、AmoebaNet`什么网络`{:.warning}）和轻量级（如 MobileNet、ShuffleNet、SqueezeNet、Xception、MobileNetV2），其中 PeleeNet 与 SSD 结合提高了速度`是 peleenet 速度高还是和 ssd 的特定结合方式提高了速度`{:.warning}；    
对视频、摄像头等实时场景对速度和精度要求都很高，需设计特定架构；     
合适的高性能分类网络可以提高目标检测的精度，因此通常会选用密集型网络，比如 FasterRCNN 中使用了 ResNet 代替 VGG 捕获了更丰富的特征`和哪个检测网络对比，证明了 ResNet 更适合用在目标检测中`{:.warning}；   

# 3 pipline
pipline：     
- **图像预处理**：resize，颜色抖动（亮度、颜色、对比度调整），翻转，旋转，缩放，裁剪，平移，添加高斯噪声；GAN 生成新图像；       
- **特征提取**：特征提取质量决定了后续的分类和回归精度；        
- **分类与回归**：给出框和类别       
- **后处理**：对弱检测结果进行处理——NMS；    

# 4 baseline
最著名的当属第一个基于 cnn 的目标检测器 RCNN；   
RCNN pipline（结构）:    
- RPN：生成候选区域（选择性搜索）     
- 特征提取：针对每个区域提取一个特征（CNN）    
- 分类：支持向量机    
- 检测框的回归    

基于 anchor 的方法有 SSD、Faster R-CNN、YOLOv2、YOLOv3 等，具有如下缺点：    
- anchor 尺寸和长宽比需要预定义，这就对数据集敏感，对检测性能影响较大；    
- 训练时，anchor 保持不变，使得预测多种尺寸物体变得困难；    
- 密集 anchor 可提高查全率，但速度和存储牺牲较大；    
- anchor 中大多为负样本，导致正负样本不均衡；    


# 5 Point   
*详细内容参见论文*    

| 技术点 | 分析 | 代表作 |
| --- | --- | --- |
| 特征提取 | **FPN**：不仅拥有丰富特征，还能预测不同尺寸的目标 | PFPNet：加宽的 FPN<br> WeaveNet 金字塔层迭代，捕获上下文特征，对单阶段检测尤为显著 |
|  | **语义关系**：区域间的语义关系可以帮助检测遮挡和小目标`为什么有助于小目标检测`{:.warning} | 加入语义分割分支和全局激活模块<br>目标外扩<br>关系模块：交互处理多个目标，并同时考虑外观和几何特征 |
|  | **注意力**：提取更适合的特征 | 全局注意力和局部结构调整助理多尺度特征融合 |
|  | **有效区域**：合理的区域特征可提高精度 | 可变形卷积；  可变形 RoIPooling |
|  | **细粒度特征** |  |
| 框的回归 | **IoU loss** | smooth L1；  general IoU |
|  | **偏移 loss** | balance L1；  Axially Localized |
| 负样本不平衡`到底是负样本不平衡，还是样本不平衡`{:.warning } | **困难样本挖掘** | OHEM；  排序后选 top n；  IoU balance 采样 |
|  | **分类损失** | focal loss；  Average-Precision loss |
| NMS | **后处理** | NMS；  fitness NMS；  adaptive NMS；  improved NMS； soft NMS； IoU NMS；   |
|  | **端到端** | relation module；  IoUNet；   |
| 速度-精度平衡 | **两阶段-单阶段结合** | 降低 head 复杂度：RefineDet |
|  | **自适应切换模型** | 判断目标检测难易，自动选择用哪个模型 |
| 小目标 | **超分辨率** | GAN； |
|  | **IoU** | 提高 IoU 阈值；<br>多个检测模块融合； |
|  | **FPN** | 改进 FPN |
| 遮挡 | **框回归** | replusion loss |
|  | **检测框架** | ORCNN； 条件随机场 |
| 目标尺寸变化 | **多尺度输入** | resize image |
|  | **多尺度（比例）** |  |
|  | **多尺度 anchor** | :FasterRCNN SSD |
| Anchor-free | **中心点+距离** | CenterNet |
| 从头训练 | **BN** |  |
| 加速 |  |  |

# 6 Classical Net
## 6.1 two stage  

| 模型 | 意义 | 创新点 |
| --- | --- | --- |
| RCNN | 开创者 | 首次证明在目标检测领域深度学习方法的有效性； <br>检测精度比传统特征（Hog特征）精度更高 |
| Fast RCNN | 速度 | 使用 RoIPooling 实现区域间特征共享；<br>使用多任务损失（分类和框回归）实现了端到端的训练；|
| Faster RCNN | 速度精度 | 用 RPN 代替选择性搜索，速度提升，且与检测网络共享特征图；<br>用多尺度 anchor 来应对多尺度目标检测；无需输入多尺度特整体即可完成多尺度目标检测；|
| Mask RCNN | 精度 | 加入分割任务，同时输出检测和分割结果；<br>特征提取用 ResNet -FPN (feature pyramid network)，并在每个金字塔层独立作出预测，提升了精度；<br>RoIAlign 替换 RoIPooling；  |

## 6.2 one stage

| 模型 | 意义 | 创新点 |
| --- | --- | --- |
| YOLO | 实时检测 | 将输入划分为 S×S 网格，网格负责中心点落在网格内的目标；<br>框预测和分类都用回归来做； |
| YOLOv2 | 训练加速和精度 | 加了 BN<br>高分辨率输入：448×448<br>引入了 anchor，去掉了预测框用的全连接层<br>从训练集聚类得到 anchor 参数<br>多尺度特征融合<br>多尺度训练<br>Darknet 19 |
| YOLOv3 | 小目标 | 多标签分类（独立的分类器）适应重迭标签<br>在三种尺度特征图上做预测<br>特征提取用 Darknet-53 |
| Retinanet | 样本不均衡 | 提出了 focal loss<br>ResNeXt-101-FPN |
| SSD | 精度 | 使用多尺度特征进行预测<br>数据扩充 |
| DSSD | 精度 | backbone：ResNet-101<br>加入了 FPN |
| RefineDet | 小目标 | 检测分两步走 |
| M2Det | 多尺度目标 | MLFPN |

`为什么会选用不同的指标`{:.warning}     
`YOLO 和 SSD 两个系列的区别是什么`{:.warning}    

## 6.3 other

| 模型 | 意义 | 创新点 |
| --- | --- | --- |
| RelationNet | 物体间的关系 | 提出目标关系模块 |
| DCNv2 | 几何形变问题 | 提出可变形卷积网络 DCN |
| NAS-FPN | 精度 | 自动搜索出的 FPN 结构 |

# 7 Dataset
## 7.1 General

| 数据集 | 介绍 | 图片数 | 类别数 | 物体数 | 度量 |
| --- | --- | --- | --- | --- | --- |
| PASCAL VOC | 2005～2012，类别间不平衡（人最多）；<br>每张图平均 2.7 个物体，1 个类别；<br>60% 的图像只有一个类别；<br>包括车辆、动物、家居用品和人 | 1.1万（0.57+0.58） | 20 | 2.7万（1.3+1.5） | AP：漏检和 FP<br>$$Recall(t)=\frac{\sum_{ij}[IoU_{ij} \ge t]  z_{ij}}{N}$$<br>$$Precision(t)=\frac{\sum_{ij}[IoU_{ij} \ge t] z_{ij}}{\sum_{ij}[IoU_{ij} \ge t]}$$ <br> $i$:图 $j$:物体，$t$ 取 0.5，$N$ 预测框的个数 |
| MS COCO | 生活场景，多视角，上下文信息丰富；<br>每个类别平均 27k 个物体，比 VOC 大；<br>每张图平均 7.7 个物体、3 个类别；<br>10% 图像只有一个类别；<br>人最多，将近 80 万；<br>71 个类别物体数量大致一样； | 32.8万 | 91 | 25万 | AP，可分别计算小中大物体 |
| ImageNet | 每张图平均 2.8 个物体、1.7 个类别；<br>60% 的图像只有一个类别； | 45/20/4万 | 200 | 47/5.5万 | $$t = \min (0.5, \frac {wh}{(w+10)(h+10)})$$ <br> 应对小目标，$w, h$ 是真实物体的宽高 |
| VisDrone2018 | 在中国 14 个城市由无人机拍摄，用于检测、跟踪；<br>标注包括目标边界框、目标类别、遮挡、截断比等<br>大量小物体，密集的汽车、行人和自行车<br>每张图超过 20 个物体； | 1万+17.9万（263个视频） |  | 250万 | COCO 标准 |
| Open Image V5 | 包括分类、检测、分割和视觉关系标注；<br>平均每张图 8 个物体； | 190万 | 600 | 1600万 | VOC 标准， 忽略未标注的类，处理了子类问题； |

*小物体需要更多的上下文推理来识别*

## 7.2 President
<center class="half">
  <img src="/assets/images/cv/detection/survey/person1.png" />&emsp;
  <img src="/assets/images/cv/detection/survey/person2.png" /><br>图1：行人检测数据集&emsp;
</center>


# 8 Application
## 8.1 业务方向

| 领域 | 方向 | 说明 | 方案 |
| --- | --- | --- | --- |
| 安防 | 人脸检测<br>行人检测<br>指纹识别<br>异常检测 | 难点在于姿态，光照和分辨率的变化<br> <br> <br>用于欺诈检测、气候分析和医疗监控； | 多任务互助；红外与可见光互补；新的 loss 函数；<br> <br> <br>MDI（最大发散区间） |
| 军事 | 遥感目标探测<br> 地形测量<br> 飞行器探测 | 难点在于图像大，目标小，背景复杂；<br>因数据分布差异大，经典网络不好用<br> <br>  | 数据融合：小目标信息少、偏差小<br>旋转和缩放不变检测<br>NWPU VHR-10、HRRSD、DOTA、VEDAI |
| 交通 | 单目<br>点云<br>融合 | 缺乏深度信息，不够精确<br>耗时<br>效果最好 | <br> <br>三维卷积+RNN 实现厘米级定位 |
| 医学 | 癌症检测<br>疾病检测<br>皮肤病检测<br>健康监测 | 个体差异显著、数据稀缺性和隐私性<br>源域和目标域之间通常存在数据分布差异 | 域自适应、注意力、LSTM（DeepMod） |
| 生活 | 智能家居<br>商品检测<br>事件检测<br>模式检测<br>雨/影检测 | <br> <br>包括：节日、演讲、抗议、自然灾害等<br>有遮挡、姿态、光照和传感器噪声等问题<br> <br> | <br> <br>多域事件检测(MED)<br>融合点云<br> <br>   |


## 8.2 技术方向

| 方向 | 描述 | 方案 |
| --- | --- | -- |
| 弱监督目标检测 | 通过分类标注训练出检测模型； | RNN，非凸问题； |
| 显著性目标检测 | 找到图片中重要的区域 | RNN |
| 高亮检测 | 视频关键帧检测，加速视频浏览，促进视频推荐； |  |
| 边缘检测 | 提取物体边缘，作为检测、分割的低层任务； | FPN |
| 文本检测 | 面临模糊、光照不均、透视失真、方位变化难题；<br>文本排列方式多变； | 检测：难以处理大的长宽比和任意排列；<br>分割：需要复杂的后处理，还不如用检测<br>用角点定位比通用检测效果好些；旋转区域也可以； |
| 多域目标检测 | 适应多个领域的通用目标检测模型； | 领域注意力；<br>迁移学习；<br>域自适应 |
| 视频目标检测 | 由于运动模糊、视频散焦等图像质量的降低，给视频中同一目标的分类带来了额外的挑战； | 单张检测，然后将不同帧的统一目标连接起来；`不是跟踪?`{:.warning} |
| 点云三维目标检测 | 点云提供了深度信息，可用于精确定位；在自主导航、自主驾驶、家政机器人和增强/虚拟现实应用中有着重要应用；<br>面临的挑战有点云稀疏、高度可变的点密度、三维空间采样不均匀、传感器有效距离、遮挡、相对位姿变化等； | 稀疏卷积层和L1正则化<br>PointNet、VoxelNet<br>单目图像进行三维目标检测<br>点云与 RGB 结合 |
| 2D、3D位姿估计 | 估计人体关节的位置 | 单阶段效果更好，也有两阶段的； |


# 9 趋势

单阶段和两阶段结合，视频目标检测（*存在运动模糊、视频散焦、运动目标模糊、目标运动剧烈、小目标、遮挡、截断等难点，在生活场景、遥感图像和体育数据中都难有好的效果*），后处理（*NMS 可能会消除定位精度高的结果*），弱监督目标检测方法，多域目标检测（*域转移*），3D目标检测，显著性目标检测，无监督目标检测，多任务学习，跨模态辅助检测，终端目标检测，医学影像与诊断，医学生物识别，遥感实时检测（*军事和农业领域*），GAN（*用于生成训练数据*）；   

------------------
[End](#head)   
{:.warning}  

# 附录
## A 术语

| 英文 | 中文 | 英文 | 中文 |
| --- | --- | --- | --- |
| backbone | 骨干网络 | pipline | 处理流程 |
|  |  |   |  |

## B 网络详细信息

**RCNN**:    
- *特征：4096维；候选区域 resize 到 227×227；CNN：5+2（卷积/全连接）；*    
- *分类：每个类别单独一个 SVM；*    
- *CNN 在 ImageNet 训练，然后在目标数据集上微调（N+1 类，N: object classes, 1: background)；*    
- *对于分类和回归均取 IoU > 0.5 为正样本，其他为负样本；*    

**FastRCNN**:    
- *全连接层用了 SVD 加速计算；*    
- *VOC 2007 数据集上 mAP 为 66.9%（R-CNN 是 66.0%）训练时间是 9.5 小时（RCNN 是 84 小时），推理时间是 320ms（R-CNN 是 47s），硬件用的是 Nvidia K40 GPU）；*       

**FasterRCNN**:    
- *VOC 2007 mAP 是 69.9%，骨干网络用 VGG，运行时间是 198ms（Fast R-CNN 是 1830ms）推理帧率是 5fps（Fast RCNN 是 0.5fps）；*    

**MaskRCNN**:    
- *使用了 1×1 卷积来改变维数；*    
- *由于高分辨率地形图对小目标的检测非常重要，而低分辨率地形图则含有丰富的语义信息，因此特征金字塔网络提取出了重要的特征；*    
- *RoIPooling 是在做量化，两种量化`哪两种`{:.warning}操作会导致 RoI 和提取的特征之间的没有对齐`为什么没有对齐`{:.warning}；*    
- *故 RoIAlign RoI 边界和框都做插值运算，然后用池化得到特征；*    
- *COCO 检测数据集上，采用 ResNet-FPN 骨干网，mAP 提升了 1.7 个点, RoIAlign 提升了 1.1 个点；*    


**YOLO**：     
- *每张图预测不到100个box（Fast R-CNN 是 2000 个）；*   
- *Titan X 单张处理下，45 fps（Fast RCNN 是 0.5fps，Faster R-CNN 是 7fps）；*   
- *CNN：24+2（卷积/全连接），ImageNet 预训练用的是 20+1+1（卷积/平均池化层/全连接）；*   
- *分类输入是 112×112,检测时输入 224×224,以捕获细粒度信息，提高检测精度；*   
- *定位精度不高，背景误报的情况比 Fast R-CNN 少3倍；VOC 上 45 fps，mAP 63.4%（Fast R-CNN：70.0%, 0.5 fps，Faster R-CNN：73.2% mAP, 7fps）；*   

**YOLOv2**：    
- *BN 加速网络的收敛，且 mAP 提升了 2%；*   
- *输入提升到 448×448，ImageNet 上分类提高了 4%；*   
- *anchor 是借鉴了 Faster RCNN 的，召回率提升了 7%，mAP 降了 0.3%；*   
- *Faster R-CNN 是经验确定 anchor 大小和长宽比的，此处提高了近 5%`哪个指标`{:.warning}；*   
- *细粒度特性：连接高分辨率与低分辨率特征，提高了 1%`哪个指标`{:.warning}； *   
- *多尺度的训练:为了使网络对不同大小的图像具有鲁棒性，每 10 批就改变一次输入图像的大小，随机地从{320,352，…608}中选取；大图检测中，YOLOv2 达到 40fps，78.6（YOLO 是 45fps，63.4%*   
- *Darknet-19：19+5（卷积层/maxpooling）提升了准确度，（ResNet 5fps，76.4%，SSD500 19fps，76.8%）；*   



**YOLOv3**：   
- *用三种不同尺度的特征来预测边界框，对小目标效果更好，但大中型目标检测能力较差`为什么小目标好了，反而大目标检测不出来了`{:.warning}；*   
- *Darknet-53 灵感来自 ResNet 来增加深度； *   
- *COCO 数据集上 YOLOv3 AP 是 33%（DSSD 513 是 33.2%），速度是 DSSD 512 的 3 倍；RetinaNet 是 40.8%；IOU = 0.5 时 YOLOv3 mAP 是 57.9%（DSSD 513 为 53.3%，RetinaNet 为 61.1%）
;*   

**RetinaNet**：       
- *克服了正负样本不均衡问题：单阶段检测器拥有密集的候选位置，而两阶段检测器中，由于第一阶段滤除了大部分的负样本框，所以精度地一阶段检测器更高`为什么更高了`{:.warning}；主要原因是单级探测器训练网络收敛时，简单样本和困难样本候选框个数极不平衡。作者就此提出  focal loss 为困难样本赋予较大权重，而减少简单样本的权重，避免训练过程中出现大量的负样本框`为什么要避免出现负样本`{:.warning}；*   
- *COCO 数据集上，ResNet-101-FPN RetinaNet AP 是 39.1%（DSSD 513 是 33.2%），ResNeXt-101-FPN AP 是 40.8%，对中小型目标的检测精度远超最优的单阶段模型（DSSD 513）；*   

**SSD**：     
- *正负样本比例控制在 1:3；*    
- *SSD 512 在 VOC 2007 测试集上实现了 81.6% 的 mAP，在 VOC 2012 上 mAP 是 80.0%（Faster R-CNN 78.8%，YOLO 57.9%）；并且在 COCO 数据集上，SSD 512 在各种测评指标下都比 Faster R-CNN 好；*   

**DSSD**：    
反卷积单阶段检测器    
- *将特征图和反卷积结果相加，提高检测精度  *   
- *在 ILSVRC CLS-LOC 数据集上训练 SSD（321×321 或 513×513），然后冻结 SSD 模块，训练 DSSD 的反卷积部分；VOC 数据集上 DSSD 提升了 2.2%；*   

**RefineDet**：   
- *预处理*   
- *检测：两步走，对困难样本，尤其是小目标效果很好*   
- *NMS*   

**M2Det**：  
- *MLFPN：多级特征金字塔网络，就是两个 FPN 堆叠，然后对两个反卷积模块结果相加得到金字塔特征；*   
- *预测部分用 SSD-VGG-16，COCO 上 mAP 41.0，速度 11.8 FPS，多尺度下达到 44.2，比 RetinaNet-Res101-FPN 800 高 0.9%，慢 RetinaNet 800 两倍；*     

**RelationNet**：    
- *目标关系模块：自适应注意力模块，考虑了图像中不同目标之间的相互作用（外观特征和几何信息）；该模块加在两个全连接层之前，提升了分类和定位的精度，且代替了 NMS 处理；*     
- *COCO 数据集上，Faster RCNN、FPN 和 DCN 上分别加入关系模块，准确度提升了0.2、0.6和0.2；*    
`NMS 时间复杂度高吗`{:.warning}     

**DCNv2**：    
- *应对物体几何变化；常规卷积只能处理方形物体`什么是可变形卷积`{:.warning}；*    
- *DCNv1 只在第五层加了形变卷积，在 COCO 上提高了 4%；mAP [0.5:0.95] 下是 37.5%*     
- *DCNv2 在 3-5 层都用了可形变卷积，同时在 RoI 部分加入了特征模仿；mAP 比 DCNv1 高了 3% ~ 5%，比 Faster RCNN 高 5% ~ 8%；*    

**NAS-FPN**：    
- *NAS-FPN：自动搜索出的新 FPN, 也就是各种 scale 组合*    
- *用 ResNet-50（256 维特征）在 COCO 数据集上，mAP 比 FPN 高了 2.9%*    
- *用 AmoebaNet（384 维特征）在 COCO 上 mAP 是 48.0%*  
`速度怎么样呢`{:.warning}

---
layout: article
title:  "「CV」 对抗攻击资源汇总"
date:   2019-07-15 17:00:40 +0800
key: adversarial-attack-foundation-20190715
aside:
  toc: true
category: [AI, CV, adversarial_attack]
tags: 资源
---
<span id='head'></span>  
>相关资源：[对抗攻击概述](/ai/cv/adversarial_attack/2019/09/03/survey.html)       

<!--more-->
# 1 综述
1. [Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey](http://cn.arxiv.org/abs/1801.00553)   
*2018-01-02* [paper](https://arxiv.org/abs/1801.00553) | [博客](https://www.jiqizhixin.com/articles/2018-03-05-4)         


# 2 理论
1. [digital_chirality](https://github.com/linzhiqiu/digital_chirality)     


# 3 经典论文
1. [Intriguing properties of neural networks](http://cn.arxiv.org/abs/1312.6199)    
*2013-12-21* Ian Goodfellow [paper](https://arxiv.org/abs/1312.6199)     
阐述了分类网络的缺陷——对攻击敏感；并给出了简单的图像扰动策略；    

# 4 检索任务
1. [Unsupervised Adversarial Attacks on Deep Feature-based Retrieval with GAN](http://cn.arxiv.org/abs/1907.05793)   
*2019-07-12* [paper](https://arxiv.org/abs/1907.05793)    


# 5 其他
1. [Explaining and Harnessing Adversarial Examples](http://cn.arxiv.org/abs/1412.6572)    
*2014-12-20* Ian Goodfellow [paper](https://arxiv.org/abs/1412.6572)    

1. [Adversarial Reprogramming of Neural Networks](http://cn.arxiv.org/abs/1806.11146)   
*2018-06-28* [paper](https://arxiv.org/abs/1806.11146)   


-------------------  
[End](#head)   
{:.warning}  

# 附录
## A 参考资料
1. 机器学习对抗性攻击报告. <https://www.aqniu.com/tools-tech/22198.html>. 2017-01-09/2019-07-15.     

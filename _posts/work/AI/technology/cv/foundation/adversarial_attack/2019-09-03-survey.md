---
layout: article
title:  "「CV」 对抗攻击概述"
date:   2019-09-03 15:00:40 +0800
key: adversarial-attack-survey-20190903
aside:
  toc: true
category: [AI, CV, adversarial_attack]
---
<span id='head'></span>  
>相关资源：[对抗攻击资源](/ai/cv/adversarial_attack/2019/07/15/foundation.html)     

<!--more-->
`adversarial perturbation` · `black-box attack` · `white-box attack` · `adversarial learning`     
`perturbation detection`    


-------------------  
[End](#head)   
{:.warning}  

# 附录
## A 参考资料
1. 机器学习对抗性攻击报告. <https://www.aqniu.com/tools-tech/22198.html>. 2017-01-09/2019-07-15.     
1. [修改一个像素，就能让神经网络识别图像出错](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650732373&idx=1&sn=5e8f0ef4357988e3a4d8374deb0919e6&chksm=871b332bb06cba3d2307cab4dbbf6b1f56ff65df4f63abf5f2552ba4d90a16157452b93768ce&scene=21#wechat_redirect)    
1. [既能欺骗机器，也能迷惑人类！Goodfellow等人提出新一代对抗样本](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650738224&idx=1&sn=dd3a9bc5b71cdc23bf92fd8816fd68f0&chksm=871aca4eb06d43585821885b7a769b7d2f9b07fbdabbfc4852c77355102af645fcff53c382c0&scene=21#wechat_redirect)    
1. [ICLR 2018七篇对抗样本防御论文被新研究攻破，Goodfellow论战](https://www.jiqizhixin.com/articles/2018-02-03-4)    
1. [综述论文：对抗攻击的12种攻击方法和15种防御方法](https://www.jiqizhixin.com/articles/2018-03-05-4)    

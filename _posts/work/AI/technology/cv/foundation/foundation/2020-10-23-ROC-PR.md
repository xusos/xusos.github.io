---
layout: article
title:  "「CV」 ROC 和 PR 曲线"
date:   2020-10-23 14:06:40 +0800
key: cv-roc-pr
aside:
  toc: true
category: [AI, CV, cv_foundation]
---
<span id='head'></span>
>ROC曲线和PR（Precision - Recall）曲线皆为类别不平衡问题中常用的评估方法   

<!--more-->

# 1. 基础概念

| 缩写 | 术语 | 实际类别 | 说明 |
| TP | 真阳性 | 正样本 |  |
| FP | 假阳性 | 负样本 | 一类错误，假报警 |
| TN | 真阴性 | 负样本 |  |
| FN | 假阴性 | 正样本 | 二类错误，未命中 |

真阳性率： $$ TPR = \frac{TP}{P} = \frac{TP}{TP + FP}$$    
假阳性率： $$ FPR = \frac{FP}{N} = \frac{FP}{FP + TN}$$    
准确率： $$ Precision = \frac{TP}{Y} = \frac{TP}{FP + TP}$$    


# 2 ROC
关于 TPR 和 FPR 的曲线 [详情](#TPR-FPR)；    
AUC (Area Under the Curve)：反映的是将正样本判为负的概率比将负样本判为正的概率大多少；           


## 2.1 优点
## 2.2 缺点

# 3 PR
以 recall 为横坐标，precision 为纵坐标绘制出 PR 曲线；    
此处，正负样本形成对抗，使得曲线越靠近左上角（正例优先于负例），模型整体表现越好（可视化之后，正负样本之间 gap 很大）；而处于随机线（主对角线）上的点则意味着，一个样本会被随机判断为正/负；          

`这里，ROC 指标表现，等于模型泛化能力更好吗`{:.warning} 并不是，因为泛化说的是评测指标在训练集和测试集上表现的差异程度；而此处，说的是 ROC 在某个数据集上的表现好，说到泛化，还是要和训练集上的指标（ROC）相比才可以；        


## 3.1 优点
- 兼顾正例（TPR）和负例（FPR）；    
- 指标不依赖于数据分布（类别间数量差异）；`什么意思，有哪个指标依赖于具体类别吗`{:.warning}    
FPR 依赖的是所有正样本，FPR 依赖所有负样本；当正负样本比例失调时，ROC 曲线也不会产生很大变化；但 Precision 同时依赖正负样本，就易受数据分布影响；    

## 3.2 缺点


-------------------  
[End](#head)
{:.warning}  


# 附录
## A 参考资料
1. 张乐乐章. PR曲线 ROC曲线的 计算及绘制[EB/OL]. <https://www.cnblogs.com/zle1992/p/6825076.html>. 2017-05-08/2020-10-23.    
ROC 的例子很好理解；    
1. massquantity. 机器学习之类别不平衡问题 (2) —— ROC和PR曲线[EB/OL]. <https://developer.aliyun.com/article/620175>. 2018-03-20/2020-10-23.    

## B 概念
<span id="TPR-FPR"> **1. ROC 曲线的形成**</span>   
以二分类为例，此处 P 的定义是置信度>阈值为正，否则为负；那么设定一个阈值得到一个 TPR——FPR 点，（0， 1）的阈值就可以得到一组点，进而绘制成 ROC 曲线；  ；我们通常使用的 softmax + argmax，其实是用的阈值 0.5；        

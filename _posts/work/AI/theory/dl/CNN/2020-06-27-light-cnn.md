---
layout: article
title:  "「DL」 轻量型卷积网络"
date:   2020-06-27 17:18:40 +0800
key: light-cnn
aside:
  toc: true
category: [AI, DL, CNN]
---
<span id='head'></span>  
>[轻量型网络资源](/ai/dl/cnn/2019/05/21/foundation.html#32-轻量级网络)、[卷积网络概述](/ai/dl/cnn/2020/07/10/survey.html)  

<!--more-->

模型压缩：量化，降维；    

# 1 轻量型网络

| 网络 | 亮点 | 说明 |
| --- | --- | --- |
| [ResNeXt](#ResNeXt) | 残差+Inception（**组卷积**） |  |
| [SqueezeNet](#squeezenet) | **通道压缩**+多分支拼接 | 速度比 AlexNet 并没有变快 |
| [TinyDarkNet](#TinyDarkNet) | - | 更快更强 |
| [Xception](#Xception) | Inception 中一个分支用 1×1 卷积 + **可分离卷积**代替了  |  |
| [ShuffleNetV1](#shufflenetv1) | 通道交互靠1×1组卷积+**通道混洗**；升维用 concate | 解决1×1卷积计算量大的问题 |
| [ShuffleNetV2](#shufflenetv2) | 用回1×1卷积，只不过先对**道拆分**，即每个分支只负责一部分通道 |  |
| [CondenseNet](#CondenseNet) | 自动学习分组 | VGG 的性能，300倍的速度； |
| [MobileNetV1](#mobilenetv1) | 可分离卷积+1×1升维代替部分卷积 |  |
| [MobileNetV2](#mobilenetv2) | 反转残差，块内用可分离卷积 |  |
| [MobileNetV3](#mobilenetv3) | 融入了 NAS |  |
| [IGCv1](#IGCv1) | k组卷积 + shuffle + n/k组卷积 | 两次组之间互补，并不快 |
| [IGCv2](#IGCv2) | - | 超级互补 |
| [IGCv3](#IGCv3) | - | 低秩 |


如何衡量网络轻量：     
*FLOPS: 浮点运算量，MAC：内存访问时间*    
广为流传的方式是 FLOPS；但影响速度的还有 MAC 和网络并行度；    
- channel in = channel out 的卷积操作 MAC 最小；`为什么`{:.warning}    
- 组卷积会导致高的 MAC；`为什么`{:.warning}   
- 网络碎片化会降低并行度，即分支越少越好；   
- 逐元素操作的 FLOPS 低，但是 MAC 高；    

*来自 shufflenetv2*    

-------------------  
[End](#head)
{:.warning}  

# 附录
## A 网络分析
<span id='ResNeXt'> </span>     

**ResNeXt**
{:.warning}
`组卷积`：block 内卷积都换成组卷积；    


<span id='squeezenet'> </span>     

**SqueezeNet**
{:.warning}
`用 1×1 卷积对通道降维`；     
fire module：先通道降维`squeeze`，然后用类似 inception 结构（1×1,3×3 感受野；concate）`expand`；      
使用全局 maxpooling 替代 fc；（这就要保证前边的卷积层把通道处理得等于类别数）`确认下`{:.warning}    
使用 DeepCompresion 压缩后，模型 0.5 M，性能不变；    

<span id='Xception'> </span>     

**Xception**
{:.warning}
>将空间和通道处理分开；   

`深度可分离卷积`（输入输出通道数相同，通道间独立；卷积是n对n的，而深度可分离是一对一的）；那么通道变化的操作就交给1×1了；参数节约量为： $$\frac{C_{in} \times k \times k + C_{in} \times C_{out}} {C_{in} \times k \times k \times C_{out}}$$    
*全连接到卷积是空间（w×h）维度降低参数量（参数共享），卷积到深度可分离是通道维度降低参数量*



<span id='mobilenetv1'> </span>     

**MobileNetV1**
{:.warning}
部分卷积换做深度可分离卷积，通道升维靠1×1；   
Relu6：激活值限制，为了满足移动端低精度部署，因为大范围会表示不了，而损失精度；`感觉不对劲`{:.warning}     
缺点：
- 只用了 VGG 式的堆叠，没有用更复杂的结构（残差，特征融合）；     
- 通道间独立，卷积核又小，导致较少的输入信息被传递；    
- Relu6 将定义域限制在 (0, 6)，这使得激活后的值很容易变 0，难以训练，从而导致部分卷积核失效；`为什么值为0,就影响训练了`{:.warning}    


<span id='mobilenetv2'> </span>    

**MobileNetV2**
{:.warning}
>吸收了残差的思想

加入残差：反转的残差（凹透镜变凸透镜，以缓解深度可分离卷积带来的特征丰富度的降低）     
每个 block 最后移除 Relu6，为了减少特征损耗；`奇怪，非线性都减少了，特征怎么还丰富了`{:.warning}    


<span id='mobilenetv3'> </span>    

**MobileNetV3**
{:.warning}
>神经网络搜索

深度可分离 + 逆转残差 + 注意力；   

用神经网络搜索功能来构建全局的网络结构（资源受限的平台感知 NAS），随后利用了 NetAdapt 算法来对每层的核数量进行优化；   
h-swish 代替 sigmoid；`有啥好处`{:.warning}       

*感觉 shuffle 的思路都很魔幻*    

<span id='shufflenetv1'> </span>    

**ShuffleNetV1**
{:.warning}
>通道混洗    

问题：1×1 卷积占用了大量计算量（mobilenet 中用于通道升维）；    
核心：用 1×1 组卷积代替 1×1 卷积以降低计算量（其中通道交互靠混洗（组卷积，组间混洗），通道升维靠 concate）；   
*混洗：reshape（行为组数）、transpose、flatten*    
用 1×1 组卷积 + 通道混洗代替 1×1 卷积；`通道增加了吗，靠concate？和1×1有啥区别`{:.warning}     
降采样的 block 尾部用 concate 代替 add；`concate 代替 add 对于特征提取的意义是什么`{:.warning}   


<span id='shufflenetv2'> </span>    

**ShuffleNetV2**
{:.warning}
>通道拆分

问题：FLOPS 低但是速度慢；    
移除 1×1 组卷积：用 1×1 卷积代替（此处为了降低计算量用 split 对分支降维，最后再 concate）；    
通道升维 + add 用 split + concate 替代；    

<span id='CondenseNet'> </span>    

**CondenseNet**
{:.warning}
VGG 相似的性能，1/50 的运算量，300倍的帧率；

<span id='IGCv1'> </span>     

**IGCv1**
{:.warning}



<span id='IGCv2'> </span>     

**IGCv2**
{:.warning}


<span id='IGCv3'> </span>     

**IGCv3**
{:.warning}


## B 参考资料
1. [攻克目标检测难点秘籍一，模型加速之轻量化网络](https://cloud.tencent.com/developer/article/1587543)    

---
layout: article
title:  "「DL」 卷积网络概述"
date:   2020-07-10 01:10:40 +0800
key:  cnn-survey
aside:
  toc: true
category: [AI, DL, CNN]
---
<span id='head'></span>  
>[卷积网络资源](/ai/dl/cnn/2019/05/21/foundation.html)     

<!--more-->

# 1 经典网络

| 模型 | 创新点 | 说明 |
| --- | --- | --- |
| [LeNet](#LeNet) | 卷积（权值共享），池化 | sigmoid |
| [AlexNet](#AlexNet) | softmax，Relu，Dropout，分组卷积，LRN |  |
| [VGG](#VGG) | 小卷积 | 多个小卷积模拟大卷积，1*1 卷积 |
| [GoogLeNet](#GoogLeNet) | 多分支 |  |
| [ResNet](#ResNet) | 残差 | 应对网络退化问题； |
| [PyramidNet](#PyramidNet) | 通道拼接 | 解决残差升维时效果不好的问题 |
| [DenseNet](#DenseNet) | 多级残差，通道拼接 |  |
| [DualPathNet](#DualPathNet) | Res+Dense：一部分用加法，剩下用拼接 |  |

# 2 [轻量型网络](/ai/dl/cnn/2020/06/27/light-cnn.html)
-------------------  
[End](#head)
{:.warning}  

# 附录
## A 参考资料

## B 经典网络


<span id='LeNet'>  </span>

**LeNet**
{:.warning}
最后三层 fc；    
输入 32*32；   

<span id='AlexNet'>  </span>

**AlexNet**
{:.warning}



<span id='VGG'>  </span>

**VGG** 
{:.warning}
多个小卷积（3×3）模拟大卷积（7×7）：参数量更少，非线性增加，表达能力更好；          
卷积层不改变尺寸，靠 pooling；    
拟合速度快；    
1×1 卷积引入更多非线性；    


<span id='GoogLeNet'>  </span>

**GoogLeNet**
{:.warning}
亮点：参数量少，卷积并联（注重宽度）；    
Inception Module：    
- 多分支得到不同的感受野；    
- bottleneck：用1×1通道降维和复原；    
- 使用全局平均池化；    

InceptionV2/3：    
*结合了 VGG；小卷积；1×k，k×1并联/串联*    
- 避免用 pooling（表达瓶颈，引起能力下降）；    
- 通道越多，信息越解耦，易局部处理，加速了拟合；    
- conv 前可以做通道压缩，表达能力变化不大；    
- 宽度深度要平衡；     

Inceptionv4：结合了残差；     

<span id='ResNet'>  </span>

**ResNet**
{:.warning}
残差：缩短反向传播路径，有效抑制梯度消失，解决网络退化问题（随着深度增加，误差升高）；    

<span id='PyramidNet'>  </span>

**PyramidNet**
{:.warning}
解决残差设计中遇到通道升维时效果不好的问题：用通道拼接代替1×1升维；或者去掉第一个激活函数，最后再来个 BN；   


<span id='Darknet'>  </span>

**Darknet**
{:.warning}
去掉全连接，最后只用一层全局平均池化代替；    
速度和精度达到较好的平衡；    

<span id='DenseNet'>  </span>

**DenseNet**
{:.warning}
残差通道拼接，多级残差；   


<span id='DualPathNet'>  </span>

**DualPathNet**
{:.warning}

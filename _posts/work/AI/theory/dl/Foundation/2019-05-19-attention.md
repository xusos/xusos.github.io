---
layout: article
title:  "「DL」 深度学习中的注意力机制"
date:   2019-05-19 13:00:40 +0800
key: attention-20190519
aside:
  toc: true
category: [AI, DL, foundation]
---
`attention`   

<!--more-->  

<center class="half">
  <img src="/assets/images/video/claaification/attention/cycling.gif" height="400"/>&emsp;<img src="/assets/images/video/claaification/attention/soccer.gif" height="400"/>&emsp;
</center>

# 1 基本概念
注意力可以分为 soft attention 和 hard attention，soft attention 可以使用梯度下降算法学习，而 hard attention 可以使用强化学习、maximizing a variational lower bound、importance sampling 算法来学习；    

# 2 原理

# 3 应用

# 附录
## A 参考资料
1. Microstrong. 深度学习中的注意力机制[EB/OL]. <https://zhuanlan.zhihu.com/p/53036028>. 2018-12-25/2019-05-19.   

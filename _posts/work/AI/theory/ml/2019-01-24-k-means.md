---
layout: article
title:  "「ML」 K 均值聚类"
date:   2019-01-24 15:10:40 +0800
key: ml-k-means-20190124
aside:
  toc: true
sidebar:
  nav: Unsupervised
category: [AI, ML, unsupervised]
---
>


:o: 简述 K 均值算法的具体步骤  
:o: K 均值算法的优缺点是什么，要如何对其进行调优  
:o: 针对 K 均值算法的缺点，有哪些改进的模型  
:o: 证明 K 均值算法的收敛性  


## 一、了解 K-Means
### 1. 定义  
基本步骤：  
- 预处理；  
- 随机选取 k 个聚类中心；  
- 定义 loss 函数；  
- 训练  
  - 更新样本  
  - 更新聚类中心  

### 2. 优缺点
缺点：  
- 受离群点和初值影响，每次结果都不稳定；  
  离群点和少量噪声都会对均值产生较大影响，导致中心点偏移；
- 结果通常是局部最优，而不是全局最优；  
- 无法很好地解决样本不均衡的情况；  
- 不太适用于离散分类；  
- 只能发现凸集（所有基于划分的聚类方法的共性）  

### 3. 优化
1） 数据归一化和离群点的处理  
2） 合理选择 K 值  
- 手肘法    
- Gap Statistic  
- 动态更新 K 值  
  ISODATA 算法：聚类过程中对类别进行合并或分裂；需事先给定初始类别 K、单个类别最少样本数、最大方差和聚类中心所允许的最小间距；  
3) 改进聚类中心的初始化
k-means++：从第二个聚类中心开始，取距离已选择的聚类中心较远的值作为下一个聚类中心；  
4） 核函数  
核聚类：针对非凸数据分布，使用核函数进行非线性映射，以提高线性可分的概率；  
5） 不希望样本被划分为单一类别  
模糊 C 聚类；高斯混合模型；  

-------------------  
 End
{:.warning}  



## 附录
### A 参考文献  
1. 诸葛越. 百面机器学习[M]. 北京:人民邮电出版社. 2018.93-101.    
1. [Scalable k-means++](https://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf)      
*2014* [paper](https://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf)     

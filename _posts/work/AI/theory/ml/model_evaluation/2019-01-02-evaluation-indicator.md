---
layout: article
title:  "「ML」性能度量"
date:   2019-01-02 16:06:40 +0800
key: performance_evaluation-20190102
aside:
  toc: true
category: [AI, ML, model_evaluation]
---

> 每个评估指标都有其价值，但如果只使用单一的指标，往往会的出片面甚至错误的结论；所以使用互补的指标才能更好地解决实际问题；  

## 基本概念
### 1. 错误率与精度

### 2. 查准率、查全率和 F1
（1） P-R 图

### 3. ROC 和 AUC

### 4. 代价敏感错误率与代价曲线

1. 分类精度
当我们使用“准确性”这个术语时，指的就是分类精度。它是正确预测数与样本总数的比值。
只有当属于每个类的样本数量相等时，它才有效。

例如，假设在我们的训练集中有98％的A类样本和2％的B类样本。然后，我们的模型可以通过简单预测每个训练样本都属于A类而轻松获得98％的训练准确性。

当在60％A级样品和40％B级样品的测试集上采用相同的模型时，测试精度将下降到60％。分类准确度很重要，但是它有时会带给我们一种错觉，使我们认为模型已经很好。

真正的问题出现在，当少量样本类被误分类造成很大的损失的情况下。如果我们处理一种罕见但致命的疾病，那么真正的患者未被诊断出疾病的造成的损失远高于健康人未被诊断出疾病。

2. 对数损失

对数损失，通过惩罚错误的分类来工作。它适用于多类分类。在处理对数损失时，分类器必须为所有样本分配属于每个类的概率。假设，有N个样本属于M类，那么对数损失的计算如下:

LogarithmicLoss
log(p„)
 
这里，
表示样本i是否属于类别j
表示样本i属于类j的概率
对数损失的值没有上限，它取值于[0，∞）范围内。对数损失接近0表示其有高的准确性，而如果对数损失远离0则表明准确度较低。


一般来说，最大限度地减少对数损失可以提高分类精度。

 
3. 混淆矩阵

混淆矩阵顾名思义，通过一个矩阵描述了模型的完整性能。

假设我们有一个二元分类问题。我们有一些样本，它们只属于两个类别:是或否。另外，我们有自己的分类器，它用来预测给定输入样本的类。我们在165个样品上测试了我们的模型，得到了如下结果:

n=165
Actual:
NO
Actual:
Predicted:
NO
50
5
Con 《 on Matrix
Predicted:
10
100
有四个重要的术语:

True Positives：我们预测“是”并且实际产出也是“是”的情况。

True Negatives：我们预测“否”和实际产出也是“是”的情况。

False Positives：我们预测“是”并且实际产出也是“否”的情况。

False Negatives：我们预测“否”并且实际产出也是“否”的情况。


矩阵的精度可以通过取过“主对角线”的平均值来计算。即，

混淆矩阵是其他度量类型的基础。

4. 曲线下面积（Area Under Curve, AUC）
曲线下面积（AUC）是评估中使用最广泛的指标之一。 它用于二分类问题。分类器的AUC等价于分类器随机选择正样本高于随机选择负样本的概率。 在定义AUC之前，让我们理解两个基本术语：

True Positive Rate (真阳性率)：它被定义为TP /（FN + TP）。 对于所有正数据点，它对应于正数据点被正确认为是正的比例。

False Positive Rate (假阳性率) :它被定为FP /（FP + TN）。即对应于所有负数据点，负数据点被错误地认为是正的比例。
False Positive Rate 和 True Positive Rate的值均在[0，1]范围内。FPR和TPR机器人在阈值如（0.00，0.02，0.04，...，1.00）下计算并绘制对应图形。AUC是[0,1]中不同点的False Positive Rate对True Positive Rate曲线下的面积。

Receiver operating characteristic example
ROC curve (area 二 0 ． 79 ）
False Positive Rate
1 ． 0
很明显，AUC的范围是[0,1]。 值越大，我们模型的性能越好。

5. F1 分数
F1分数用于衡量测试的准确性

F1分数是精确度和召回率之间的调和平均值（Harmonic Mean）。 F1分数的范围是[0，1]。 它会告诉您分类器的精确程度（正确分类的实例数），以及它的稳健程度（它不会错过大量实例）；

高精度和低召回率，会带来高的精度，但也会错过了很多很难分类的实例。 F1得分越高，我们模型的表现越好。 在数学上，它可以表示为：

F1分数试图找到精确度和召回率之间的平衡。
Precision :它是正确的正结果的数目除以分类器所预测的正结果的数目。
Recall：它是正确的正结果的数量除以所有相关样本(即所有应该被识别为正结果的样本)的数量。

6. 平均绝对误差

平均绝对误差是原始值与预测值之差的平均值。 它衡量预测与实际输出还差多远。 但是，它们并没有给我们提供任何关于错误方向的信息，即不能给出我们的模型到底是低于预测数据还是高于预测数据。 在数学上，它表示为：

7. 均方误差
均方误差（MSE）与平均绝对误差非常相似，唯一的区别是MSE取原始值与预测值之差的平方的平均值。 MSE的优点是计算梯度更容易，而平均绝对误差需要复杂的线性编程工具来计算梯度。 由于我们采用误差的平方，更大的误差的影响变得更明显，因此模型现在可以更多地关注更大的误差；


## Q&A
### 1. 准确率的局限性

### 2. 精确率与召回率的权衡

### 3. 平方根误差的“意外”

### 4. 什么是 ROC 曲线

### 5. 如何绘制 ROC 曲线

### 6. 如何计算 AUC

### 7. ROC 曲线相比 P-R 曲线有什么特点

## 附录
### A 参考资料
[1]. 诸葛越, et al. 百面机器学习[M]. 北京:人民邮电出版社, 2018.22-33.  
[2]. 周志华. 机器学习[M]. 北京:清华大学出版社, 2016.28-35.  
